\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

%\usepackage{nips_2016}

\PassOptionsToPackage{options}{natbib}
%\usepackage[nonatbib]{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage[final,nonatbib]{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{amssymb}
\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\usepackage{dsfont}
\usepackage{upgreek}
\usepackage{bm}
\usepackage{stmaryrd}
\usepackage{amsmath}
\usepackage{lipsum}  
\usepackage{amsmath}
\usepackage{tabularx}
\usepackage{color}
\usepackage{textcomp}
\usepackage{dsfont}
\usepackage[english]{babel}
%\usepackage[square,numbers]{natbib}

\title{Application of Machine Learning Methods for Classification of False and Misleading News}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Kelly L. Geyer\\
  Department of Statistics\\
  Rice University\\
  Houston, Texas 77005 \\
  \texttt{klg2@rice.edu} \\
  %% examples of more authors
  \And
  %% Coauthor \\
  Nathan Osborne \\
  Department of Statistics\\
  Rice University\\
  Houston, Texas 77005 \\
  \texttt{klg2@rice.edu} \\
  \And
  Arjoon Srikanth \\
  Department of Statistics\\
  Rice University\\
  Houston, Texas 77005 \\
  \texttt{as135@rice.edu} \\
  \And
  %% Coauthor \\
  Hao Wang \\
  Department of Statistics\\
  Rice University\\
  Houston, Texas 77005 \\
  \texttt{klg2@rice.edu} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
% AS original abstract
%  Accompanying the spread of easily shareable news articles and In recent years, with the widespread adoption of social media as a means of mass news distribution, it has become extremely common for news with biased, misleading, or even outright false headlines and content to go mainstream and viral.This deluge of “fake news” threatens to irreparably undermine the public’s trust of online media and journalism, and unfortunately, a meta-analysis of over 200 different studies confirmed that humans are only 4\% better than chance at determining fact from falsehood (Bond \& DePaulo, et al 2006). So far, several machine learning techniques have been proposed to filter “fake news” but such work has largely been the purview of the media and journalists, and the use of learning has not become mainstream in the field. To further l that end, we have constructed a dataset by scraping websites that are known and documented for distributing false, biased, or misleading headlines and articles, which each article represented in Java Script Object Notation. We then separated the data into a training set for use in giving the giving the classifier prior data from which to act upon, as well as a testing set for ascertaining the effectiveness of the model thereof. Feature extraction, that is, intelligently selecting which elements of the article/associated metadata would act as the best predictors for categorization, would be the next step. We then implemented the specific machine learning models themselves, tuned to the features we predicted would be the most significant, specifically a Naive Bayes model, a Support Vector Machine, and a Logistic Regression Model. Each of these is a binary classifier, whereas we were attempting to classify articles into one or more of five different categories, namely credible, false, bias, satire, and political. This necessitates some creativity in comparing and determining an articles likelihood to be a member of a certain category. The most effective models, measured through a receiver operating characteristic curve, have been . The most powerful predictors of article category have been . 
 
 
Accompanying the spread of easily shareable news articles in recent years, with the widespread adoption of social media as a means of mass news distribution, it has become extremely common for news with biased, misleading, or even false content to become mainstream. This deluge of “fake news” threatens to irreparably undermine the public’s trust of online media and journalism. 

So far, several machine learning techniques have been proposed to filter “fake news” but such work has largely been the purview of the media and journalists, and the use of learning has not become mainstream in the field. 

To further that end, we have constructed a dataset by scraping websites that are known and documented for distributing false, biased, or misleading headlines and articles, which each article represented in Java Script Object Notation. We then separated the data into a training set for use in giving the giving the classifier prior data from which to act upon, as well as a testing set for ascertaining the effectiveness of the model thereof. Feature extraction, that is, intelligently selecting which elements of the article/associated metadata would act as the best predictors for categorization, would be the next step. We then implemented the specific machine learning models themselves, tuned to the features we predicted would be the most significant, specifically a Naive Bayes model, a Support Vector Machine, and a Logistic Regression Model. Each of these is a binary classifier, whereas we were attempting to classify articles into one or more of five different categories, namely credible, false, bias, satire, and political. This necessitates some creativity in comparing and determining an articles likelihood to be a member of a certain category. The most effective models, measured through a receiver operating characteristic curve, have been . The most powerful predictors of article category have been . 
\end{abstract}

\section{Introduction}

\textbf{Background and Motivation}

While the issue of mass false news distribution has been an issue as long as print media has been around, the advent of social media has irreversably expanded the scope, reach, and speed of these misleading news stories. A particularly egregious example of this proliferation can be found in the bizarre allegations during the 2016 United States Presidential campaign where, taken from sparse and decontextualized electronic communications that had been leaked, it was highly popularized that members of the campaign staff of Hilary Clinton were involved in an illicit sexual slavery ring based out of a pizza restaurant. This falsified and sensationalized story was widely distributed through a conspiracy site known as InfoWars, and proved to be nearly fatal as a man wielding a semiautomatic weapon, entered the establishment and claimed to be "saving the children." While this is an extreme example of the effect that massively distributed "fake news," as it has been dubbed, can have, what is more contemptuous is the smaller lies and falsehoods spread by dubious sites with nearly convincing names and website domains, intended primarily for the casual glance on social media, rather than any prolonged examination. The everyday to exposure to such falsehoods can have a multitude of effects, the most pressing of which are the tendencies to the extreme, i.e. either to accept all information on one's social media feed to be true, or to doubt all media and discard useful information outright. With the assumption that a free and functioning democracy is predicated on open and thoughtful discourse, it is clear that these are outcomes that one would hope to avoid. \par
Our purpose with this research is to contribute to the ongoing study on how we may responsibly and effectively filter out blatantly false news sources, but additionally how we may delineate false news sources from satirical outlets, political news sites, and potentially extremely ideologically biased news sources. There have been a multitude of sociological papers on the advent of these news sites, and the motives that would lead one to believe or fabricate such content, however, in comparison relatively little has been done in the specific field of false news detection. Henceforth will be detailed a survey of papers and heretofore attempts at classification. A relatively recent and simple attempt to fight back against misleading content comes in the form of web browser plugins, such as "Fake News Detector" and the "Signal Media" plugin. These are simple plugins that operate through a list of URLs that are marked as "false", "bias", "credible", etc. and alert a user if they happen upon one of the sites. While these may do well for the most well known and established sites, they suffer in crucial areas, namely that they operate via list, and additions to the list happen through an open source project format that will not be updated as fast as fake news sites are published. A huge issue with false and misleading news sites is the ease by which a domain name can be purchased and structured to look like a credible news site. By merely examining an article's URL, rather than content, these plugins quickly become susceptible to rapid obsolescence due to their lack of currency. Therefore, a huge motivation for this project was the need for a classifier that would not only look at the URL, but also the content of the article itself before classification so that given a website that the classifier has never before encountered, a basic understanding of its characteristics can be provided. \par
Conroy et al. have detailed a survey of several methods, some of which have been previously shown to be effective at classifying false statements. They describe two major categories of methods: Linguistic Approaches, which focus on content of texts and analysis to determine patterns, and the Network Approaches, where article metadata, or alternatively a knowledge network such as a database, provide aggregate deception measures. They incorporate machine learning techniques to train classifiers. So far there is no known rigorous typology of methods in current literature. \par
The linguistic approach makes use of “predictive deception cues” in the content of the text. The simplest method of representing text is as a bag of words approach, where every word is significant. Individual words and n-gram frequencies can be recorded and analyzed to find cues of deception. Part of speech tagging, or shallow syntax, provide frequency sets to reveal cues. The drawback is the lack of context that comes from isolating n-grams, but this method can also be useful in tandem with others. One may also analyze deeper syntax, using Probability Context Free Grammars, which are sentences that have been converted to parse trees, with probabilities assigned. These can be used with 85-91 \% accuracy to detect deception. Once again, alone, these methods may not be sufficient to identify deception, and studies have combined the approach with other techniques.An extension of this method can be found in semantic analysis, wherein attribute:descriptor pairs are compared to existing analogous data, known as a content profile. For example, if the author claims that an art museum is near a hotel, this can potentially be compared to geographic data, or product/business reviews which may or may not present evidence to the contrary. This method has been shown to be 91 \% accurate; however, associating attributes and descriptors can be challenging without sufficient data, and finding content profile with confirmed correct information is itself a daunting task. Rhetorical Structure Theory provides an analytic framework for identifying rhetorical relations between linguistic elements. Systematic differences between true and false messages can be combined with a Vector Space Model that calculates a message vector’s distance from a truth center and a deceptive center. This model makes use of prominent rhetorical relations found in deceptive texts to be indicative of deception.
Support Vector Machines and Naïve Bayesian models are examples of classifiers that utilize sets of words and category frequencies to train them. They predict deception by using numeric clustering and distances. Naïve Bayes algorithms note accumulated evidence of correlations between one variable and the others in the model. Classification results from unintended emotional cues and syntactic evidence resulting from exaggeration of the sentiment required of deception. Network approaches can complement linguistic approaches, especially with the advent of sites such as twitter. Knowledge networks, such as DBpedia or the Google Relation Extraction Corpus, are used to analyze false “factual statements” by calculating a simple shortest path, to find semantic proximity. The shorter the path, the more likely the claim is factual. One challenge with this method is the reliance on a pre-existing knowledge base. Another network based method involves the use of metadata and “telltale behavior” of questionable sources, such as the inclusion of hyperlinks or associated metadata, which can be compiled. Centering resonance analysis can be used to link the most important words that link other words in the network.Combining network with linguistic methods adds the “trust” element by identifying source behavior beyond simply content. Additionally, data is much needed in this field, and is a worthwhile contribution on its own. \par
	Many of these previously described methods have been shown to be successful in some contexts but not others, but as has been previously stated, there has not been a rigorous classification of methods in this field as of yet. Another of the main goals for the project was determining and differentiating classification methods by effectiveness. Another of the biggest challenges for this field cited by Conroy et al. is the lack of published datasets for this field. To that end, we have assembled a large dataset of hundreds of thousands of articles, with associated metadata and their credibility classification to be published with our work for the benefit of the field of fake news detection. \par
	Another paper by Horne and Adalt gives a very specific example of classification research in the field. They have assembled and published a dataset themselves, along with a classifier they created using numerous linguistic features to classify articles on a scale from real to fake using a linear kernel Support Vector Machine, coming to the conclusion that content widely differs between real and fake sources. Additionally, their conclusions were that the title was the most significant predictor when it came to classifying real vs. fake news, citing that false and misleading news titles are often longer and jam in many more claims than their articles even address. From this paper, a few of the textual features used in our research have been obtained, detailed as follows. \par
	A simple and naive linguistic approach to classification would merely use textual frequencies, such as n-grams to verify their predictive power, however, these are often heavily skewed and dependent on document size, so much so that they may not even be useful. A much more useful measure used to rectify this issue is text frequency-inverse document frequency or TF-IDF, which weights frequency by document length by logarithmically scaling text frequency in one document depending on its prevalence in the corpus. Another potentially useful measure comes in the form of sentiment analysis, wherein positive and negative words, and so-called emphatic terms are measured to classify a document in relation to a positive and negative pole. The point of this statistic is to determine an article's objectivity in presenting information, which can play a role in determining a biased source. Measures along the lines of text frequency that have been cited by the previous study include: number of adverbs, number of personal pronouns and number of nouns themselves. Horne and Adalt's research reveals these statistics to widely differ between credible and non credible sources, making them ideal candidates for prediction. Other useful metrics include the Fleisch-Kincaid measures of both readability as well as Grade Level analysis, both of which are algorithms used to determine the level of vocabulary and complexity of the sentences used in text content. Unsurprisingly, Horne and Adalt recorded that while satirical and credible news sources tend to have relatively similar readability scores and Grade Levels; however, fake news have been shown to have readability scores and grade levels lower than either of those two. Along these lines, our project has adopted the use of n-grams, which are collections with length n of words in sequence throughout the document, weighted using TF-IDF. 

\section{Methodology}
\label{gen_inst}

Perhaps the most challenging element of this effort is determining a safe and objective definition for what can be reasonably considered false and misleading news itself. To that end, we consulted existing resources on the subject; as mentioned earlier, browser plugins have already determined sites known for disseminating fallacious, as well as reliable articles and compiled them in a data structure mapping site names to categories of content they are known for publishing. The five categories we chose to examine were credible, false, biased, political, and satirical. Credible news sources are those which are generally trusted and produce relatively objective content, false denotes those which have been created intentionally to mislead the public, biased sources are ideologically bent and cover current events with an overt agenda, satire are those news sources that openly identify as publishing false content for the purposes of amusement, and political sources cover news with the purposes of promoting a political party. Many online publishers had more than one category associated with them. This research project acknowledges the difficulty in objectively determining the degree to which any one site can be known to produce content that conforms to one category or the other; however, given the open source nature of these browser plugins, we have been able to independently confirm that much deliberation and research has been put into these classifications. The intention of this project has been to improve upon the usage of URLs as classifiers through the additional usage of text features present in  both the titles and articles themselves. \par
Now, given a list of publishers and categories of content that they are known to publish, we tasked  ourselves with scraping these webpages in search of articles, and many data points that could be reasonably associated with them. Using the python library BeautifulSoup ver. 4, websites were crawled through and articles were collected regularly to keep our database reasonably up to date with new content. After assembling this dataset, we collected from X sources for a total of Y articles, stored in a cloud based database. This dataset has been published alongside our research in the hopes that further work will be done in this field using it. \par
Next, extensive research was done on selecting previously. Specifically, we decided upon the use of n-grams weighted through TF-IDF. Our analysis pipeline was constructed through a conversion of the article's text and titles into word vectors, which specifically requires the replacement and/or removal of non-sentential punctuation, repetitions, and tags from the text, and then lemmatizing the text, that is, removing grammatical markers from the ends of words, i.e. removing pluralization, tense etc. 
After formatting the text in this manner, a vocabulary dictionary was produced from the summation of the text documents. 








\section{Theory}
\label{headings}

All headings should be lower case (except for first word and proper
nouns), flush left, and bold.

First-level headings should be in 12-point type.

\subsection{Headings: second level}

Second-level headings should be in 10-point type.

\subsubsection{Headings: third level}

Third-level headings should be in 10-point type.

\paragraph{Paragraphs}

There is also a \verb+\paragraph+ command available, which sets the
heading in bold, flush left, and inline with the text, with the
heading followed by 1\,em of space.

\section{Empirical Studies}
\label{others}

These instructions apply to everyone.

\subsection{Citations within the text}

The \verb+natbib+ package will be loaded for you by default.
Citations may be author/year or numeric, as long as you maintain
internal consistency.  As to the format of the references themselves,
any style is acceptable as long as it is used consistently.

The documentation for \verb+natbib+ may be found at
\begin{center}
  \url{http://mirrors.ctan.org/macros/latex/contrib/natbib/natnotes.pdf}
\end{center}
Of note is the command \verb+\citet+, which produces citations
appropriate for use in inline text.  For example,
\begin{verbatim}
   \citet{hasselmo} investigated\dots
\end{verbatim}
produces
\begin{quote}
  Hasselmo, et al.\ (1995) investigated\dots
\end{quote}

If you wish to load the \verb+natbib+ package with options, you may
add the following before loading the \verb+nips_2016+ package:
\begin{verbatim}
   \PassOptionsToPackage{options}{natbib}
\end{verbatim}

If \verb+natbib+ clashes with another package you load, you can add
the optional argument \verb+nonatbib+ when loading the style file:
\begin{verbatim}
   \usepackage[nonatbib]{nips_2016}
\end{verbatim}

As submission is double blind, refer to your own published work in the
third person. That is, use ``In the previous work of Jones et
al.\ [4],'' not ``In our previous work [4].'' If you cite your other
papers that are not widely available (e.g., a journal paper under
review), use anonymous author names in the citation, e.g., an author
of the form ``A.\ Anonymous.''

\subsection{Footnotes}

Footnotes should be used sparingly.  If you do require a footnote,
indicate footnotes with a number\footnote{Sample of the first
  footnote.} in the text. Place the footnotes at the bottom of the
page on which they appear.  Precede the footnote with a horizontal
rule of 2~inches (12~picas).

Note that footnotes are properly typeset \emph{after} punctuation
marks.\footnote{As in this example.}

\subsection{Figures}

All artwork must be neat, clean, and legible. Lines should be dark
enough for purposes of reproduction. The figure number and caption
always appear after the figure. Place one line space before the figure
caption and one line space after the figure. The figure caption should
be lower case (except for first word and proper nouns); figures are
numbered consecutively.

You may use color figures.  However, it is best for the figure
captions and the paper body to be legible if the paper is printed in
either black/white or in color.
\begin{figure}[h]
  \centering
  \fbox{\rule[-.5cm]{0cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
  \caption{Sample figure caption.}
\end{figure}

\subsection{Tables}

All tables must be centered, neat, clean and legible.  The table
number and title always appear before the table.  See
Table~\ref{sample-table}.

Place one line space before the table title, one line space after the
table title, and one line space after the table. The table title must
be lower case (except for first word and proper nouns); tables are
numbered consecutively.

Note that publication-quality tables \emph{do not contain vertical
  rules.} We strongly suggest the use of the \verb+booktabs+ package,
which allows for typesetting high-quality, professional tables:
\begin{center}
  \url{https://www.ctan.org/pkg/booktabs}
\end{center}
This package was used to typeset Table~\ref{sample-table}.

\begin{table}[t]
  \caption{Sample table title}
  \label{sample-table}
  \centering
  \begin{tabular}{lll}
    \toprule
    \multicolumn{2}{c}{Part}                   \\
    \cmidrule{1-2}
    Name     & Description     & Size ($\mu$m) \\
    \midrule
    Dendrite & Input terminal  & $\sim$100     \\
    Axon     & Output terminal & $\sim$10      \\
    Soma     & Cell body       & up to $10^6$  \\
    \bottomrule
  \end{tabular}
\end{table}

\section{Conclusions}

Do not change any aspects of the formatting parameters in the style
files.  In particular, do not modify the width or length of the
rectangle the text should fit into, and do not change font sizes
(except perhaps in the \textbf{References} section; see below). Please
note that pages should be numbered.

\section{Preparing PDF files}

Please prepare submission files with paper size ``US Letter,'' and
not, for example, ``A4.''

Fonts were the main cause of problems in the past years. Your PDF file
must only contain Type 1 or Embedded TrueType fonts. Here are a few
instructions to achieve this.

\begin{itemize}

\item You should directly generate PDF files using \verb+pdflatex+.

\item You can check which fonts a PDF files uses.  In Acrobat Reader,
  select the menu Files$>$Document Properties$>$Fonts and select Show
  All Fonts. You can also use the program \verb+pdffonts+ which comes
  with \verb+xpdf+ and is available out-of-the-box on most Linux
  machines.

\item The IEEE has recommendations for generating PDF files whose
  fonts are also acceptable for NIPS. Please see
  \url{http://www.emfield.org/icuwb2010/downloads/IEEE-PDF-SpecV32.pdf}

\item \verb+xfig+ "patterned" shapes are implemented with bitmap
  fonts.  Use "solid" shapes instead.

\item The \verb+\bbold+ package almost always uses bitmap fonts.  You
  should use the equivalent AMS Fonts:
\begin{verbatim}
   \usepackage{amsfonts}
\end{verbatim}
followed by, e.g., \verb+\mathbb{R}+, \verb+\mathbb{N}+, or
\verb+\mathbb{C}+ for $\mathbb{R}$, $\mathbb{N}$ or $\mathbb{C}$.  You
can also use the following workaround for reals, natural and complex:
\begin{verbatim}
   \newcommand{\RR}{I\!\!R} %real numbers
   \newcommand{\Nat}{I\!\!N} %natural numbers
   \newcommand{\CC}{I\!\!\!\!C} %complex numbers
\end{verbatim}
Note that \verb+amsfonts+ is automatically loaded by the
\verb+amssymb+ package.

\end{itemize}

If your file contains type 3 fonts or non embedded TrueType fonts, we
will ask you to fix it.

\subsection{Margins in \LaTeX{}}

Most of the margin problems come from figures positioned by hand using
\verb+\special+ or other commands. We suggest using the command
\verb+\includegraphics+ from the \verb+graphicx+ package. Always
specify the figure width as a multiple of the line width as in the
example below:
\begin{verbatim}
   \usepackage[pdftex]{graphicx} ...
   \includegraphics[width=0.8\linewidth]{myfile.pdf}
\end{verbatim}
See Section 4.4 in the graphics bundle documentation
(\url{http://mirrors.ctan.org/macros/latex/required/graphics/grfguide.pdf})

A number of width problems arise when \LaTeX{} cannot properly
hyphenate a line. Please give LaTeX hyphenation hints using the
\verb+\-+ command when necessary.

\subsubsection*{Acknowledgments}

Use unnumbered third level headings for the acknowledgments. All
acknowledgments go at the end of the paper. Do not include
acknowledgments in the anonymized submission, only in the final paper.

\section*{References}

References follow the acknowledgments. Use unnumbered first-level
heading for the references. Any choice of citation style is acceptable
as long as you are consistent. It is permissible to reduce the font
size to \verb+small+ (9 point) when listing the references. {\bf
  Remember that you can use a ninth page as long as it contains
  \emph{only} cited references.}
\medskip

\small

% Arjoon's citations
[1] Alexander, J.A.\ \& Mozer, M.C.\ (1995) Template-based algorithms
for connectionist rule extraction. In G.\ Tesauro, D.S.\ Touretzky and
T.K.\ Leen (eds.), {\it Advances in Neural Information Processing
  Systems 7}, pp.\ 609--616. Cambridge, MA: MIT Press.

[2] Bower, J.M.\ \& Beeman, D.\ (1995) {\it The Book of GENESIS:
  Exploring Realistic Neural Models with the GEneral NEural SImulation
  System.}  New York: TELOS/Springer--Verlag.

[3] Hasselmo, M.E., Schnell, E.\ \& Barkai, E.\ (1995) Dynamics of
learning and recall at excitatory recurrent synapses and cholinergic
modulation in rat hippocampal region CA3. {\it Journal of
  Neuroscience} {\bf 15}(7):5249-5262.
  
[4] Conroy, Niall J., Victoria L. Rubin, and Yimin Chen. "Automatic Deception Detection: Methods for Finding Fake News." Proceedings of the Association for Information Science and Technology 52.1 (2015): 1-4. Web.

[5] Horne, Benjamin D., Adah Sibel. "This Just In:Fake News Packs a Lot in Title , Uses Simpler,Repetitive Content in Text Body,More Similar to Satire than Real News." 

  
Examples of internal citation in Latex \\
In the paper \cite{pls2}, the following conclusions were drawn....
 
  
\medskip
\bibliographystyle{unsrt}
\bibliography{sample}

\end{document}
